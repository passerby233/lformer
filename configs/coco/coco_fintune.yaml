model:
  base_learning_rate: 1.0e-04 # no_effect wit OneCycle
  max_steps: 800 # 300K steps budget
  target: taming.models.crosslformer.CrossLformerLatent
  params:
    css: 32
    w_layer: 12
    text_drop: 0.1
    ckpt_path: /home/ma-user/work/lijiacheng/archive/cc3m_finetune/checkpoints/last.ckpt
    transformer_config:
      target: taming.modules.transformer.sparse.SparseGPT
      params:
        dim_cond: 512 # num of dimensions of condition hidden
        block_size: 1024
        text_vbs: 0
        img_vbs: 2887
        n_layer: 24
        n_head: 16
        n_embd: 1536
        embd_pdrop: 0.1
        resid_pdrop: 0.1
        attn_pdrop: 0.1
        full_head: False
        add_cross: True # Add cross attention
        PBrelax: True # To keep stable for >24 layers if on
        checkpoint: 12
    text_encoder_config:
      target: taming.models.custom_clip.TextEncoder
      params: 
        ckpt_path: /home/ma-user/work/lijiacheng/pretrained/ViT-B-16.pt
        freeze: True
        
    # taming VQGAN Openimages Shrinked to 2887
    first_stage_config:
      target: taming.models.vqgan.ShrinkVQ
      params:
        ckpt_path: /home/ma-user/work/lijiacheng/vqmodel/openimages/last.ckpt
        mapping_path: /home/ma-user/work/lijiacheng/vqmodel/openimages/taming_vqvae_2887.pt
        kl_weight: 1.0e-08
        embed_dim: 256
        n_embed: 8192
        monitor: val/rec_loss
        temperature_scheduler_config:
          target: third_party.scheduler.scheduler.LambdaWarmUpCosineScheduler
          params:
            warm_up_steps: 0
            max_decay_steps: 1000001
            lr_start: 0.9
            lr_max: 0.9
            lr_min: 1.0e-06
        ddconfig:
          double_z: false
          z_channels: 256
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1,1,2,4]
          num_res_blocks: 2
          attn_resolutions: [32]
          dropout: 0.0
        lossconfig:
          target: third_party.losses.vqperceptual.DummyLoss

data:
  target: taming.data.utils.DataModuleFromConfig
  params:
    batch_size: 16
    num_workers: 8
    train:
      target: taming.data.coco.COCOFeature
      params:
        split: train
        img_size: 256
        crop_size: 256
        img_root: /cache/coco/train2017
        meta: /home/ma-user/work/lijiacheng/data/coco/metadata_coco_train.pkl
        fea: /home/ma-user/work/lijiacheng/data/coco/feature_coco_clip_train.pkl
    validation:
      target: taming.data.coco.COCOFeature
      params:
        img_size: 256
        crop_size: 256
        split: test
        img_root: /cache/coco/val2017
        meta: /home/ma-user/work/lijiacheng/data/coco/metadata_coco_val.pkl
        fea: /home/ma-user/work/lijiacheng/data/coco/feature_coco_clip_val.pkl
