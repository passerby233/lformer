model:
  base_learning_rate: 1.0e-06 # no_effect wit OneCycle
  max_epochs: 50 # 50K steps budget
  scheduler_params:
    type: OneCycle
    max_lr: 1.0e-4
    pct_start: 0.02
  target: taming.models.crosslformer.CrossLformerLatent
  params:
    css: 32
    w_layer: 12
    transformer_config:
      target: taming.modules.transformer.sandwich.GPT
      params:
        dim_cond: 512 # num of dimensions of condition hidden
        block_size: 1024
        text_vbs: 0
        img_vbs: 2887
        n_layer: 24
        n_head: 16
        n_embd: 1024
        embd_pdrop: 0.1
        resid_pdrop: 0.1
        attn_pdrop: 0.1
        full_head: False
        add_cross: True # Add cross attention
        PBrelax: False # To keep stable for >24 layers if on
        checkpoint: 24
    text_encoder_config:
      target: taming.models.custom_clip.TextEncoder
      params: 
        ckpt_path: /home/ma-user/work/lijiacheng/pretrained/clip/ViT-B-16.pt
        freeze: True
        
    # taming VQGAN Openimages Shrinked to 2887
    first_stage_config:
      target: taming.models.vqgan.ShrinkVQ
      params:
        ckpt_path: /home/ma-user/work/lijiacheng/vqmodel/openimages/last.ckpt
        mapping_path: /home/ma-user/work/lijiacheng/vqmodel/openimages/taming_vqvae_2887.pt
        kl_weight: 1.0e-08
        embed_dim: 256
        n_embed: 8192
        monitor: val/rec_loss
        temperature_scheduler_config:
          target: third_party.scheduler.scheduler.LambdaWarmUpCosineScheduler
          params:
            warm_up_steps: 0
            max_decay_steps: 1000001
            lr_start: 0.9
            lr_max: 0.9
            lr_min: 1.0e-06
        ddconfig:
          double_z: false
          z_channels: 256
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1,1,2,4]
          num_res_blocks: 2
          attn_resolutions: [32]
          dropout: 0.0
        lossconfig:
          target: third_party.losses.vqperceptual.DummyLoss

data: #CC3M
  target: taming.data.utils.DataModuleFromConfig
  params:
    batch_size: 16
    num_workers: 8
    train:
      target: taming.data.cc3m.CC3MFeature
      params:
        split: train
        img_root: /cache/cc3m/
        meta: /cache/cc3m/metadata_cc3m.pkl
        fea: /cache/cc3m/feature_cc3m_clip_train.pkl
    validation:
      target: taming.data.coco.COCOFeature
      params:
        split: test
        img_root: /cache/cc3m/val2017
        meta: /cache/cc3m/metadata_coco_val.pkl
        fea: /cache/cc3m/feature_cc3m_clip_val.pkl
